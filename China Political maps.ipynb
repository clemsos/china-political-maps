{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from slugify import slugify\n",
    "\n",
    "import pymongo\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.readwrite import write_gpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_slug(name, type):\n",
    "    \"\"\" get a clean string ID from name and type\"\"\"\n",
    "    return \"%s-%s\"%(slugify( name.decode('utf-8') ),type.decode('utf-8'))\n",
    "\n",
    "\n",
    "def create_node(name, type, start, end, orga=None, info=None) : \n",
    "    \"\"\"create the node at the right format in the main graph\"\"\"\n",
    "    slug = get_slug(name, type)\n",
    "    \n",
    "    try :\n",
    "        if start > G.node[slug][\"start\"] : start =  G.node[slug][\"start\"]\n",
    "        if end > G.node[slug][\"end\"] : start =  G.node[slug][\"end\"]\n",
    "    except:\n",
    "        start = start\n",
    "        end = end\n",
    "            \n",
    "    node = {}\n",
    "    node[\"id\"] = slug\n",
    "    node[\"type\"] = type\n",
    "    node[\"orga\"] = orga # cluster or ARC ?\n",
    "    node[\"name\"] = name\n",
    "    node[\"start\"] = start\n",
    "    node[\"end\"] = end\n",
    "    \n",
    "    if info :\n",
    "        node[\"info\"]=info\n",
    "    \n",
    "    G.add_node(node[\"id\"], node)\n",
    "    return node[\"id\"]\n",
    "\n",
    "def merge_edge_data(Graph, e, data):\n",
    "    \"\"\"\n",
    "    merge data properly :prevent data within existing edges to be erased\n",
    "    \"\"\"\n",
    "    try : \n",
    "        Graph.edge[e[0]][e[1]]\n",
    "    except KeyError:\n",
    "        Graph.add_edge(e[0], e[1])\n",
    "        \n",
    "    try:\n",
    "        Graph.edge[e[0]][e[1]][\"edge_types\"].append(data)\n",
    "    except KeyError:\n",
    "        Graph.edge[e[0]][e[1]][\"edge_types\"] = [data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Fetch data from the copy of database\n",
    "\n",
    "Previously extracted from China Vitae website (on Feb, 21 - 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to mongo\n",
    "client = pymongo.MongoClient('localhost', 27017)\n",
    "db = client.chinaVitae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network of locations\n",
    "\n",
    "For each person :\n",
    "\n",
    "* create a node corresponding to locations\n",
    "* ignore institutions (for now)\n",
    "* create an edge between nodes for each common person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419 nodes, 9105 edges \n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations \n",
    "\n",
    "G = nx.Graph() # main graph\n",
    "\n",
    "for bio in db.biographies.find():#.limit(1000):\n",
    "    nodes = []\n",
    "    for row in bio[\"career\"]:\n",
    "        for link in row[\"links\"]:\n",
    "            \n",
    "            if link[\"type\"] == \"location\":\n",
    "                try : \n",
    "                    # create node\n",
    "                    node = create_node(\n",
    "                        link[\"name\"], \n",
    "                        link[\"type\"], \n",
    "                        row[\"start\"], \n",
    "                        row[\"end\"], \n",
    "                        info={ \"url\" : link[\"url\"] }\n",
    "                    )\n",
    "\n",
    "                    nodes.append(node)\n",
    "\n",
    "                except UnicodeEncodeError:\n",
    "                    print \"UnicodeEncodeError\"\n",
    "        \n",
    "        \n",
    "    # create edges\n",
    "    for e in list(combinations(set(nodes), 2)):\n",
    "        merge_edge_data(G, e, { \"name\" : bio[\"name\"], \"mongo_id\" : bio[\"_id\"]} )\n",
    "\n",
    "print \"%s nodes, %s edges \"%(len(G.nodes()), len(G.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "region_pages = []\n",
    "\n",
    "for n in G.nodes(data=True):\n",
    "    if \"region\" in n[0] or \"province\" in n[0]: \n",
    "        region_pages.append((n[0], n[1][\"info\"][\"url\"]))\n",
    "\n",
    "# for stats\n",
    "unknown_slugs = []\n",
    "all_slugs = []\n",
    "\n",
    "# parse subregions index\n",
    "sub_to_regions = {}\n",
    "for r in region_pages:\n",
    "    region_slug = r[0]\n",
    "    path = \"data/regions/\"+region_slug+\".json\"\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            sub_regions = json.load(f)\n",
    "        \n",
    "        for sub in sub_regions[\"children\"]:\n",
    "            slug = get_slug(sub[\"short_name\"], \"location\")\n",
    "            all_slugs.append(slug)\n",
    "            try: \n",
    "                G[slug]\n",
    "                sub_to_regions[slug] = region_slug\n",
    "            except KeyError:\n",
    "                unknown_slugs.append(slug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 nodes, 193 edges \n"
     ]
    }
   ],
   "source": [
    "# create graph by region\n",
    "G_by_regions = nx.Graph()\n",
    "\n",
    "# create nodes\n",
    "\n",
    "for r in region_pages:\n",
    "    slug = r[0]\n",
    "    G_by_regions.add_node(slug)\n",
    "    \n",
    "\n",
    "for e in G.edges():\n",
    "    if e[0] in sub_to_regions.keys() and e[1] in sub_to_regions.keys():\n",
    "        source = sub_to_regions[e[0]]\n",
    "        target = sub_to_regions[e[1]]\n",
    "        \n",
    "        if G_by_regions.has_edge(source, target):\n",
    "            G_by_regions[source][target]['weight'] += 1\n",
    "        else:\n",
    "            G_by_regions.add_edge(source, target, weight=1)\n",
    "        \n",
    "\n",
    "print \"%s nodes, %s edges \"%(len(G_by_regions.nodes()), len(G_by_regions.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 nodes\n",
      "193 edges\n"
     ]
    }
   ],
   "source": [
    "# create the graph\n",
    "\n",
    "nodes = []\n",
    "for n in G_by_regions.nodes(data=True): \n",
    "    if G_by_regions.degree(n[0]) > 0: # ignore singletons\n",
    "        node = G.node[n[0]]\n",
    "        node[\"id\"] = n[0]\n",
    "        nodes.append(node)\n",
    "\n",
    "print \"%s nodes\"%len(nodes)\n",
    "        \n",
    "edges = []\n",
    "for i, e in enumerate(G_by_regions.edges(data=True)): \n",
    "    \n",
    "    edge = e[2] \n",
    "    edge[\"source\"] = e[0]\n",
    "    edge[\"target\"] = e[1]\n",
    "    \n",
    "    edges.append(edge)\n",
    "\n",
    "print \"%s edges\"%len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A topogram with the same name already exists\n",
      "nodes deleted\n",
      "edges deleted\n",
      "27 nodes created.\n",
      "193 edges created.\n",
      "done. Topogram is online at https://app.topogram.io/topograms/PYCHNaBubGHLErZXo/view\n"
     ]
    }
   ],
   "source": [
    "# send regions graph to topogram\n",
    "\n",
    "from topogram_client import TopogramAPIClient\n",
    "import logging \n",
    "import datetime\n",
    "\n",
    "now=datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "# passwords\n",
    "TOPOGRAM_URL = \"https://app.topogram.io\" # http://localhost:3000\n",
    "USER = \"clement.renaud@epfl.ch\"\n",
    "PASSWORD = \"makerspaces\"\n",
    "\n",
    "# connect to the topogram instance \n",
    "topogram = TopogramAPIClient(TOPOGRAM_URL)\n",
    "\n",
    "# topogram.create_user(USER, PASSWORD)\n",
    "topogram.user_login(USER, PASSWORD)\n",
    "\n",
    "r = topogram.create_topogram(\"China Political Networks\")\n",
    "print r[\"message\"]\n",
    "topogram_ID = r[\"data\"][0][\"_id\"]\n",
    "\n",
    "# get and backup existing nodes and edges\n",
    "existing_nodes = topogram.get_nodes(topogram_ID)[\"data\"]\n",
    "existing_edges = topogram.get_edges(topogram_ID)[\"data\"]\n",
    "\n",
    "# clear existing graph\n",
    "topogram.delete_nodes([n[\"_id\"] for n in existing_nodes])\n",
    "print \"nodes deleted\"\n",
    "topogram.delete_edges([n[\"_id\"] for n in existing_edges])\n",
    "print \"edges deleted\"\n",
    "\n",
    "r = topogram.create_nodes(topogram_ID, nodes)\n",
    "print \"%s nodes created.\"%len(r[\"data\"])\n",
    "r = topogram.create_edges(topogram_ID, edges)\n",
    "print \"%s edges created.\"%len(r[\"data\"])\n",
    "\n",
    "print \"done. Topogram is online at %s/topograms/%s/view\"%(TOPOGRAM_URL, topogram_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
